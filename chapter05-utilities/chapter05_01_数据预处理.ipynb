{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /F ./data/dogcat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **自定义的数据集需要继承Dataset**  \n",
    "- **并且实现**\n",
    "    - __getitem__\n",
    "    - __len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/dogcat/cat.12484.jpg',\n",
       " './data/dogcat/cat.12485.jpg',\n",
       " './data/dogcat/cat.12486.jpg',\n",
       " './data/dogcat/cat.12487.jpg',\n",
       " './data/dogcat/dog.12496.jpg',\n",
       " './data/dogcat/dog.12497.jpg',\n",
       " './data/dogcat/dog.12498.jpg',\n",
       " './data/dogcat/dog.12499.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = './data/dogcat/'\n",
    "imgs = os.listdir(root)\n",
    "imgs = [os.path.join(root,img) for img in imgs]\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCat(data.Dataset):\n",
    "    \n",
    "    def __init__(self,root):\n",
    "        imgs = os.listdir(root)\n",
    "        # 不实际加载图片，只是指定路径，当调用__getitem__时才会真正读图片\n",
    "        self.imgs = [os.path.join(root,img) for img in imgs] \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img_path = self.imgs[index]\n",
    "        label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "        pil = Image.open(img_path) # open\n",
    "        array = np.asarray(pil) # array\n",
    "        data = t.from_numpy(array) # tensor\n",
    "        return data,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 497, 3]) 0\n",
      "torch.Size([499, 379, 3]) 0\n",
      "torch.Size([236, 289, 3]) 0\n",
      "torch.Size([374, 499, 3]) 0\n",
      "torch.Size([375, 499, 3]) 1\n",
      "torch.Size([375, 499, 3]) 1\n",
      "torch.Size([377, 499, 3]) 1\n",
      "torch.Size([400, 300, 3]) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "dataset = DogCat('./data/dogcat/')\n",
    "# img,label = dataset[0]\n",
    "for data,label in dataset:\n",
    "    print(data.size(),img.float().mean(),label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torchvision.transforms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfrom = T.Compose([\n",
    "    T.Resize(224), # 缩放图片(Image)，保持长宽比不变，最短边为224像素\n",
    "    T.CenterCrop(224), # 从图片中间切出224*224的图片\n",
    "    T.ToTensor(), # 将图片(Image)转成Tensor，归一化至[0, 1]\n",
    "    T.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]) # 标准化至[-1, 1]，规定均值和标准差\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) tensor(-0.1655) 0\n",
      "torch.Size([3, 224, 224]) tensor(0.3892) 0\n",
      "torch.Size([3, 224, 224]) tensor(0.0711) 0\n",
      "torch.Size([3, 224, 224]) tensor(-0.0462) 0\n",
      "torch.Size([3, 224, 224]) tensor(-0.0649) 1\n",
      "torch.Size([3, 224, 224]) tensor(0.1176) 1\n",
      "torch.Size([3, 224, 224]) tensor(0.2234) 1\n",
      "torch.Size([3, 224, 224]) tensor(-0.0267) 1\n"
     ]
    }
   ],
   "source": [
    "class DogCat(data.Dataset):\n",
    "    \n",
    "    def __init__(self,root,transfrom=None):\n",
    "        imgs = os.listdir(root)\n",
    "        # 不实际加载图片，只是指定路径，当调用__getitem__时才会真正读图片\n",
    "        self.imgs = [os.path.join(root,img) for img in imgs]\n",
    "        self.transform = transfrom\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img_path = self.imgs[index]\n",
    "        label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "        data = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "dataset = DogCat('./data/dogcat/',transfrom=transfrom)\n",
    "for img, label in dataset:\n",
    "    print(img.size(), img.float().mean(),label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ImageFolder**  \n",
    "假设所有的文件按文件夹保存，每个文件夹下存储同一个类别的图片，文件夹名为类名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /F  ./data/dogcat_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0, 'dog': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImageFolder('./data/dogcat_2/')\n",
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0][1]) # 第一张label\n",
    "dataset[0][0] # 第一张图（Image对象）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.4, 0.4, 0.4], std=[0.2, 0.2, 0.2])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImageFolder('./data/dogcat_2/', transform=transform)\n",
    "dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_img = T.ToPILImage()\n",
    "to_img(dataset[0][0]*0.2+0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoader**  \n",
    "- Dataset只负责数据的抽象，一次调用__getitem__只返回一个样本\n",
    "- 在训练神经网络时，最好是对一个batch的数据进行操作，同时还需要对数据进行shuffle和并行加速等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 224, 224])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可迭代对象\n",
    "dataloader = DataLoader(dataset,batch_size=3,shuffle=True,num_workers=0,drop_last=False)\n",
    "dataiter = iter(dataloader)\n",
    "imags,labels = next(dataiter)\n",
    "imags.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果某张图片损坏无法读取**  \n",
    "- 过滤：这种情况下dataloader返回的batch数目会少于batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCat(data.Dataset):\n",
    "    \n",
    "    def __init__(self,root,transfrom=None):\n",
    "        imgs = os.listdir(root)\n",
    "        # 不实际加载图片，只是指定路径，当调用__getitem__时才会真正读图片\n",
    "        self.imgs = [os.path.join(root,img) for img in imgs]\n",
    "        self.transform = transfrom\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        try:\n",
    "            img_path = self.imgs[index]\n",
    "            label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "            data = Image.open(img_path)\n",
    "            if self.transform:\n",
    "                data = self.transform(data)\n",
    "            return data,label\n",
    "        except:\n",
    "            return None,None # 返回空对象\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate # 导入默认的拼接方式\n",
    "\n",
    "def my_collate_fn(batch): # batch-->(data,label)\n",
    "    \n",
    "    batch = list(filter(lambda x:x[0] is not None,batch))\n",
    "    if len(batch)==0:\n",
    "        return t.Tensor() # tensor([])\n",
    "    return default_collate(batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DogCat('data/dogcat_wrong/', transfrom=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_img(dataset[0][0]*0.2+0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 224])\n",
      "torch.Size([2, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([2, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset,2,collate_fn=my_collate_fn,num_workers=0,shuffle=True,drop_last=True)\n",
    "for data,label in dataloader:\n",
    "    print(data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随机取一张图片代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCat(data.Dataset):\n",
    "    \n",
    "    def __init__(self,root,transfrom=None):\n",
    "        imgs = os.listdir(root)\n",
    "        # 不实际加载图片，只是指定路径，当调用__getitem__时才会真正读图片\n",
    "        self.imgs = [os.path.join(root,img) for img in imgs]\n",
    "        self.transform = transfrom\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        try:\n",
    "            img_path = self.imgs[index]\n",
    "            label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "            data = Image.open(img_path)\n",
    "            if self.transform:\n",
    "                data = self.transform(data)\n",
    "            return data,label\n",
    "        except:\n",
    "            new_index = random.randint(0,len(self)-1)\n",
    "            return self[new_index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sampler**  \n",
    "用来对数据进行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DogCat('./data/dogcat/',transfrom=transform)\n",
    "\n",
    "w = [2 if label==1 else 1 for data,label in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import  WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(weights,num_samples=9,replacement=True)\n",
    "dataloader = DataLoader(dataset,batch_size=3,sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torchvision**  \n",
    "- models\n",
    "- datasets\n",
    "- transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预训练模型位置：  \n",
    "- win:C:\\Users\\wensh\\.cache\\torch\\hub\\checkpoints\n",
    "- linux:~/.torch/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to C:\\Users\\wensh/.cache\\torch\\hub\\checkpoints\\squeezenet1_1-f364aa15.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdce2be1aad14b2c92168a67089b6cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4966400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "resnet34 = models.squeezenet1_1(pretrained=True)\n",
    "resnet34.fc=nn.Linear(512,10) # 修改最后的全连接层为10分类问题（默认是ImageNet上的1000分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "# 通过train=False获取测试集\n",
    "dataset = datasets.MNIST('data/', download=True, train=False,transform=transform)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "to_pil(t.randn(3, 64, 64))\n",
    "to_img = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.9882, 0.9882, 0.9882],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.9882, 0.9882, 0.9882],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.9882, 0.9882, 0.9882]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1020, 0.1020, 0.1020]]]]),\n",
       " tensor([5, 4, 6, 7, 4, 4, 7, 9, 7, 6, 9, 4, 3, 5, 6, 5])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset,shuffle=True,batch_size=16)\n",
    "\n",
    "from torchvision.utils import make_grid,save_image\n",
    "dataiter = iter(dataloader)\n",
    "img = make_grid(next(dataiter)[0], 4) # next(dataiter) --> (data,label)\n",
    "to_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
