{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0253,  0.4461, -0.5702, -2.3491,  0.1095])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.randn(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor,ToPILImage\n",
    "\n",
    "to_tensor = ToTensor()\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "img = Image.open('./img/lena.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = to_tensor(img)\n",
    "print(input.size())\n",
    "input.unsqueeze_(0) # 增加维度\n",
    "print(input.size())\n",
    "\n",
    "# 锐化卷积核\n",
    "kernel = t.ones(3,3)/-9\n",
    "kernel[1][1] = 1\n",
    "conv = nn.Conv2d(1,1,(3,3),1,bias=False)\n",
    "conv.weight.data = kernel.view(1,1,3,3)\n",
    "\n",
    "out = conv(input)\n",
    "to_pil(out.data.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.AvgPool2d(2,2)\n",
    "out = pool(input)\n",
    "to_pil(out.data.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**循环神经网络层(RNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5306, -1.1300, -0.6734, -0.7669],\n",
       "         [-0.7029,  0.9896, -0.4482,  0.8927],\n",
       "         [-0.6043,  1.0726,  1.0481,  1.0527]],\n",
       "\n",
       "        [[-0.6424, -1.2234, -1.0794, -0.6037],\n",
       "         [-0.7926, -0.1414, -1.0225, -0.0482],\n",
       "         [ 0.6610, -0.8908,  1.4793, -0.3934]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.manual_seed(1000)\n",
    "input = t.randn(2, 3, 4) # 输入：batch_size=3，序列长度都为2，序列中每个元素占4维\n",
    "lstm = nn.LSTM(4,3,1) # lstm输入向量4维，隐藏元3，1层\n",
    "# 初始状态：1层，batch_size=3，3个隐藏元\n",
    "h0 = t.randn(1, 3, 3)\n",
    "h0 = t.randn(1, 3, 3)\n",
    "output,hn = lstm(input,(h0,c0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**优化器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,6,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(params=net.parameters(),lr=1)\n",
    "net.zero_grad() # optimier.zero_grad()\n",
    "\n",
    "input = t.randn(1,3,32,32)\n",
    "output = net(input)\n",
    "output.backward(output)\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为不同子网络设置不同的学习率，在finetune中经常用到\n",
    "# 如果对某个参数不指定学习率，就使用最外层的默认学习率\n",
    "optimizer = optim.SGD([\n",
    "    {'params':net.features.parameters()},\n",
    "    {'params':net.classifier.parameters(),'lr':1e-2}\n",
    "],lr=1e-5)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只为两个全连接层设置较大的学习率，其余层的学习率较小\n",
    "specaial_layers = nn.ModuleList([\n",
    "    net.classifier[0],\n",
    "    net.classifier[2]\n",
    "]) # layer List的是ModuleList\n",
    "\n",
    "specaial_layers_params = list(map(id,specaial_layers.parameters()))\n",
    "# print(len(list(specaial_layers.parameters())))\n",
    "# specaial_layers_params\n",
    "base_params = filter(lambda p:id(p) not in specaial_layers_params,\n",
    "                    net.parameters())\n",
    "optimizer = optim.SGD([\n",
    "    {'params':base_params},\n",
    "    {'params':specaial_layers.parameters(),'lr':0.01}\n",
    "],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**调整学习率**\n",
    "- 修改optimizer.param_groups中对应的学习率\n",
    "- 新建优化器（对于使用动量的优化器（如Adam），会丢失动量等状态信息，可能会造成损失函数的收敛出现震荡等情况）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法1: 调整学习率，新建一个optimizer\n",
    "old_lr = 0.1\n",
    "optimizer1 =optim.SGD([\n",
    "                {'params': net.features.parameters()},\n",
    "                {'params': net.classifier.parameters(), 'lr': old_lr*0.1}\n",
    "            ], lr=1e-5)\n",
    "optimizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法2: 调整学习率, 手动decay, 保存动量\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.1\n",
    "    \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nn.functional**\n",
    "- 模型有可学习的参数，最好用nn.Module\n",
    "- 虽然dropout操作也没有可学习操作，但建议还是使用nn.Dropout而不是nn.functional.dropout\n",
    "- 对于有可学习参数的模块，也可以用functional来代替，需要手动定义参数parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**保存模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "t.save(net.state_dict(), 'net.pth')\n",
    "\n",
    "# 加载已保存的模型\n",
    "net2 = Net()\n",
    "net2.load_state_dict(t.load('net.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
